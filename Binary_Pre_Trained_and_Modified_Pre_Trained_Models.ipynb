{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary_Pre-Trained and Modified Pre-Trained Models.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP9JjA/P5dLkuTzUMJ7BwSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akaraci/LargeDatasetCovid19/blob/main/Binary_Pre_Trained_and_Modified_Pre_Trained_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCJDdNzTS6ew"
      },
      "source": [
        "%load_ext autotime\n",
        "import tensorflow as tf \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
        "import pickle\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import scikitplot as skplt\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "#from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn import metrics\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "np.random.seed(1000)\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import  ImageDataGenerator, img_to_array, load_img\n",
        "from glob import glob\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SunXRIu9Sagi"
      },
      "source": [
        "##------------Modified and unmodified Pre-trained Architectures's (VGG16, VGG19, InceptionV3 and Resnet50) Binary Class Code ---------------- \n",
        "X=pickle.load(open(\"drive/My Drive/LargeDataSetBen/X_databen_two_az.pickle\", \"rb\"))\n",
        "y=pickle.load(open(\"drive/My Drive/LargeDataSetBen/Y_databen_two_az.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0   \n",
        "#X = X.astype(\"float32\")/255.0  \n",
        "y = to_categorical(y, num_classes = 2)\n",
        "\n",
        "\n",
        "\n",
        "#Unmodified Pre-trained Architectures\n",
        "def buildmodel_pretrained_architecture():\n",
        "  base_model=InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
        "  #base_model=ResNet50(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "  #base_model=VGG19(include_top=False,weights='imagenet', input_shape=(224,224,3))\n",
        "  #base_model=VGG16(include_top=False,weights='imagenet', input_shape=(224,224,3))\n",
        "  base_model.trainable=True\n",
        "  model=Sequential()\n",
        "  model.add(base_model)\n",
        "  model.add(GlobalAveragePooling2D())  #for InceptionV3 and Resnet50\n",
        "  \"\"\"model.add(Flatten())   #for VGG16 and VGG19\n",
        "  model.add(Dense(4096))\n",
        "  model.add(Dense(4096))\"\"\"\n",
        "  numberOfClass=2\n",
        "  model.add(Dense(numberOfClass,activation='softmax'))\n",
        "  return model\n",
        "\n",
        "#Modified Pre-trained Architectures\n",
        "def buildmodel_modified_pretrained_architecture():\n",
        "  #base_model=InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
        "  #base_model=ResNet50(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "  base_model=VGG19(include_top=False,weights='imagenet', input_shape=(224,224,3))\n",
        "  #base_model=VGG16(include_top=False,weights='imagenet', input_shape=(224,224,3))\n",
        "  base_model.trainable=False\n",
        "  model=Sequential()\n",
        "  model.add(base_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(32))\n",
        "  model.add(Dense(64))\n",
        "  model.add(Dense(128))\n",
        "  model.add(Dense(256))\n",
        "  numberOfClass=2\n",
        "  model.add(Dense(numberOfClass,activation='softmax'))\n",
        "  return model\n",
        "\n",
        "kacfold=5\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=kacfold, shuffle=True)\n",
        "sumaccuracy=0\n",
        "sumrecall=0\n",
        "sumprecision=0\n",
        "sumf1=0\n",
        "owerlapconf_mat=0\n",
        "history=[]\n",
        "acc_val=[]\n",
        "result=[]\n",
        "aucs = []\n",
        "tprs = []\n",
        "fprs = []\n",
        "base_fpr = np.linspace(0, 1, 101)\n",
        "plt.figure(figsize=(10, 10))\n",
        "fold=1\n",
        "opt=keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "k=5\n",
        "if (k==0):opt =tf.optimizers.Adam(lr=0.0001)\n",
        "if (k==1):opt=tf.optimizers.Adadelta(lr=0.01, rho=0.95, epsilon=None, decay=0.0)\n",
        "if (k==2):opt =tf.optimizers.SGD(lr=0.01, clipnorm=1.)\n",
        "if (k==3):opt =tf.optimizers.RMSprop(lr=0.001, rho=0.8, epsilon=None, decay=0.0)\n",
        "if (k==4):opt=tf.optimizers.Adamax(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "if (k==5):opt=tf.optimizers.Nadam(lr=0.00002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    \n",
        "    x_train = X[train_index]\n",
        "    y_train = y[train_index]\n",
        "    x_test = X[test_index]\n",
        "    y_test = y[test_index]\n",
        "    model1=buildmodel_modified_pretrained_architecture()\n",
        "    #model1=buildmodel_pretrained_architecture()\n",
        "    model1.compile(loss=\"binary_crossentropy\", optimizer=opt,  metrics=[\"accuracy\"])\n",
        "    history = model1.fit(x_train, y_train, batch_size=32,epochs=60, verbose=0) \n",
        "    np.save(\"drive/My Drive/LargeDataSetBen/modelsmodify/deneme\"+str(fold)+\".npy\",history.history)  \n",
        "    prediction=model1.predict(x_test)\n",
        "    Y_pred_classes =np.argmax(prediction,axis = 1) \n",
        "    y_test_classes =np.argmax(y_test,axis = 1)\n",
        "    result=metrics.classification_report(y_test_classes, Y_pred_classes, digits=4,output_dict=True)\n",
        "    result2=metrics.classification_report(y_test_classes, Y_pred_classes, digits=4,output_dict=False)\n",
        "    sumaccuracy=sumaccuracy+result['accuracy']\n",
        "    sumrecall=sumrecall+result['weighted avg']['recall']\n",
        "    sumprecision=sumprecision+result['weighted avg']['precision']\n",
        "    sumf1=sumf1+result['weighted avg']['f1-score']\n",
        "    conf_mat =confusion_matrix(y_test_classes, Y_pred_classes, labels=[0, 1])\n",
        "    owerlapconf_mat=owerlapconf_mat+conf_mat\n",
        "    print('\\n',conf_mat)\n",
        "    print(result2)\n",
        "\n",
        "    probas_ = model1.predict_proba(x_test)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test_classes, probas_[:, 1],drop_intermediate=False,pos_label=1)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    print(\"Auc-\"+str(fold)+\"=\",roc_auc)\n",
        "    aucs.append(roc_auc)\n",
        "    plt.plot(fpr, tpr, lw=1, alpha=0.3,label='ROC Fold- %d (AUC = %0.2f)' % (fold, roc_auc))\n",
        "    tpr = np.interp(base_fpr, fpr, tpr)\n",
        "    tpr[0] = 0.0\n",
        "    tprs.append(tpr)\n",
        "\n",
        "    fold=fold+1\n",
        "meanaccuracy=sumaccuracy/kacfold\n",
        "print(\"Mean Accuracy=\",meanaccuracy)\n",
        "print(\"Mean weighted avg Recall=\",sumrecall/kacfold)\n",
        "print(\"Mean weighted avg Precision=\",sumprecision/kacfold)\n",
        "print(\"Mean weighted avg F1-Score=\",sumf1/kacfold)\n",
        "print('\\nOwerlap Confusion Matrix:\\n',owerlapconf_mat)\n",
        "total1=sum(sum(owerlapconf_mat))\n",
        "owrecall=owerlapconf_mat[1,1]/(owerlapconf_mat[1,1]+owerlapconf_mat[1,0])\n",
        "owspecifity=owerlapconf_mat[0,0]/(owerlapconf_mat[0,0]+owerlapconf_mat[0,1])\n",
        "owprecisionnormal=owerlapconf_mat[0,0]/(owerlapconf_mat[0,0]+owerlapconf_mat[1,0])\n",
        "owprecisioncovid=owerlapconf_mat[1,1]/(owerlapconf_mat[1,1]+owerlapconf_mat[0,1])\n",
        "owf1normal=2*(owspecifity*owprecisionnormal)/(owspecifity+owprecisionnormal)\n",
        "owf1covid=2*(owrecall*owprecisioncovid)/(owrecall+owprecisioncovid)\n",
        "print(\"Owerlap Recall=\",owrecall)\n",
        "print(\"Owerlap Specificity=\",owspecifity)\n",
        "print(\"Owerlap Normal Precision=\",owprecisionnormal)\n",
        "print(\"Owerlap Covid Precision=\",owprecisioncovid)\n",
        "print(\"Owerlap Normal F1-Score=\",owf1normal)\n",
        "print(\"Owerlap Covid F1-Score=\",owf1covid)\n",
        "\n",
        "tprs = np.array(tprs)\n",
        "mean_tprs = tprs.mean(axis=0)\n",
        "mean_auc = metrics.auc(base_fpr, mean_tprs)\n",
        "std = tprs.std(axis=0)\n",
        "\n",
        "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
        "tprs_lower = mean_tprs - std\n",
        "std_auc = np.std(aucs)\n",
        "plt.plot(base_fpr, mean_tprs, \n",
        "          label='Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
        "          lw=2, alpha=.8)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)    \n",
        "plt.xlim([-0.01, 1.01])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.xlabel('False Positive Rate',fontsize=18)\n",
        "plt.ylabel('True Positive Rate',fontsize=18)\n",
        "plt.title('Cross-Validation ROC of Model-4 ')\n",
        "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYFN6BGQXoPb"
      },
      "source": [
        "#%load_ext autotime\n",
        "import json,codecs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "n=np.load(\"drive/My Drive/LargeDataSetBen/modelsmodify/my_historytwol2.npy\",allow_pickle='TRUE').item()\n",
        "\n",
        "#np.save(\"drive/My Drive/Datacovid_kemal/my_history\"+str(fold)+\".npy\",history.history)\n",
        "#n=history.history\n",
        "plt.plot(n['loss'],label='train loss')\n",
        "#plt.plot(n['accuracy'],label='train acc')\n",
        "#plt.plot(n['val_loss'],label='validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(n['accuracy'],label='train acc')\n",
        "#plt.plot(n['val_accuracy'],label='validation acc')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_eKVK1cBVNd"
      },
      "source": [
        "pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ng7I-erM8c2"
      },
      "source": [
        "!pip install ipython-autotime"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}