{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi_Class_Pre-Trained and Modified Pre-Trained Models_.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNr5RCzdnQAQ1TSu7063B3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akaraci/LargeDatasetCovid19/blob/main/Multi_Class_Pre_Trained_and_Modified_Pre_Trained_Models_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCJDdNzTS6ew"
      },
      "source": [
        "%load_ext autotime\n",
        "import tensorflow as tf \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "import pickle\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import scikitplot as skplt\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "#from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn import metrics\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "np.random.seed(1000)\n",
        "\n",
        "from keras.applications.vgg19 import VGG19,preprocess_input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import  ImageDataGenerator, img_to_array, load_img\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SunXRIu9Sagi"
      },
      "source": [
        "#------------Modified and unmodified Pre-trained Architectures's (VGG16, VGG19, InceptionV3 and Resnet50) Multi Class Code ---------------- \n",
        "from sklearn.preprocessing import label_binarize\n",
        "from itertools import cycle\n",
        "\n",
        "X=pickle.load(open(\"drive/My Drive/LargeDataSetBen/X_databen_three_az.pickle\", \"rb\"))\n",
        "y=pickle.load(open(\"drive/My Drive/LargeDataSetBen/Y_databen_three_az.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0  \n",
        "y = to_categorical(y, num_classes = 3)\n",
        "\n",
        "#Unmodified Pre-trained Architectures\n",
        "def buildmodel_pretrained_architecture():\n",
        "  base_model=InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
        "  #base_model=ResNet50(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "  #base_model=VGG19(include_top=False,weights='imagenet', input_shape=(224,224,3))\n",
        "  #base_model=VGG16(include_top=False,weights='imagenet', input_shape=(224,224,3))\n",
        "  base_model.trainable=True\n",
        "  model=Sequential()\n",
        "  model.add(base_model)\n",
        "  model.add(GlobalAveragePooling2D())  #for InceptionV3 and Resnet50\n",
        "  \"\"\"model.add(Flatten())   #for VGG16 and VGG19\n",
        "  model.add(Dense(4096))\n",
        "  model.add(Dense(4096))\"\"\"\n",
        "  numberOfClass=3\n",
        "  model.add(Dense(numberOfClass,activation='softmax'))\n",
        "  return model\n",
        "\n",
        "#Modified Pre-trained Architectures\n",
        "def buildmodel_modified_pretrained_architecture():\n",
        "  #base_model=InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
        "  #base_model=ResNet50(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "  #base_model=VGG19(include_top=False,weights='imagenet', input_shape=(224,224,3))\n",
        "  base_model=VGG16(include_top=False,weights='imagenet', input_shape=(224,224,3))\n",
        "  base_model.trainable=True\n",
        "  model=Sequential()\n",
        "  model.add(base_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64))\n",
        "  model.add(Dense(128))\n",
        "  model.add(Dense(256))\n",
        "  numberOfClass=3\n",
        "  model.add(Dense(numberOfClass,activation='softmax'))\n",
        "  return model\n",
        "\n",
        "k=1\n",
        "if (k==0):opt =tf.optimizers.Adam(lr=0.001)\n",
        "if (k==1):opt=tf.optimizers.Adadelta(lr=0.01, rho=0.95, epsilon=None, decay=0.0)\n",
        "if (k==2):opt = tf.optimizers.SGD(lr=0.01, clipnorm=1.)\n",
        "if (k==3):opt =tf.optimizers.RMSprop(lr=0.001, rho=0.8, epsilon=None, decay=0.0)\n",
        "if (k==4):opt=tf.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "if (k==5):opt=tf.optimizers.Nadam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "\n",
        "kacfold=5\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=kacfold, shuffle=False)\n",
        "sumaccuracy=0\n",
        "sumrecall=0\n",
        "sumprecision=0\n",
        "sumf1=0\n",
        "owerlapconf_mat=0\n",
        "history=[]\n",
        "acc_val=[]\n",
        "result=[]\n",
        "plt.figure(figsize=(10, 10))\n",
        "fold=1\n",
        "#opt=keras.optimizers.Adam(lr=0.001)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    \n",
        "    x_train = X[train_index]\n",
        "    y_train = y[train_index]\n",
        "    x_test = X[test_index]\n",
        "    y_test = y[test_index]\n",
        "    model=buildmodel_modified_pretrained_architecture()\n",
        "    #model=buildmodel_pretrained_architecture()\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, batch_size=32, epochs=50, verbose=0) \n",
        "    np.save(\"drive/My Drive/LargeDataSetBen/modelsmodify/my_history_deneme\"+str(fold)+\".npy\",history.history)\n",
        "    prediction = model.predict(x_test)\n",
        "    Y_pred_classes = np.argmax(prediction,axis = 1) \n",
        "    y_test_classes = np.argmax(y_test,axis = 1)\n",
        "    result=metrics.classification_report(y_test_classes, Y_pred_classes, digits=4,output_dict=True)\n",
        "    result2=metrics.classification_report(y_test_classes, Y_pred_classes, digits=4,output_dict=False)\n",
        "    sumaccuracy=sumaccuracy+result['accuracy']\n",
        "    sumrecall=sumrecall+result['weighted avg']['recall']\n",
        "    sumprecision=sumprecision+result['weighted avg']['precision']\n",
        "    sumf1=sumf1+result['weighted avg']['f1-score']\n",
        "    conf_mat =confusion_matrix(y_test_classes, Y_pred_classes, labels=[0, 1, 2])\n",
        "    owerlapconf_mat=owerlapconf_mat+conf_mat\n",
        "    print('\\n',conf_mat)\n",
        "    print(result2)\n",
        "    fold=fold+1\n",
        "meanaccuracy=sumaccuracy/kacfold\n",
        "print(\"Mean Accuracy=\",meanaccuracy)\n",
        "print(\"Mean weighted avg Recall=\",sumrecall/kacfold)\n",
        "print(\"Mean weighted avg Precision=\",sumprecision/kacfold)\n",
        "print(\"Mean weighted avg F1-Score=\",sumf1/kacfold)\n",
        "print('\\nOwerlap Confusion Matrix:\\n',owerlapconf_mat)\n",
        "total1=sum(sum(owerlapconf_mat))\n",
        "owrecallnormal=owerlapconf_mat[0,0]/(owerlapconf_mat[0,0]+owerlapconf_mat[0,1]+owerlapconf_mat[0,2])\n",
        "owrecallcovid=owerlapconf_mat[1,1]/(owerlapconf_mat[1,1]+owerlapconf_mat[1,0]+owerlapconf_mat[1,2])\n",
        "owrecallpneumonia=owerlapconf_mat[2,2]/(owerlapconf_mat[2,2]+owerlapconf_mat[2,0]+owerlapconf_mat[2,1])\n",
        "\n",
        "owprecisionnormal=owerlapconf_mat[0,0]/(owerlapconf_mat[0,0]+owerlapconf_mat[1,0]+owerlapconf_mat[2,0])\n",
        "owprecisioncovid=owerlapconf_mat[1,1]/(owerlapconf_mat[1,1]+owerlapconf_mat[0,1]+owerlapconf_mat[2,1])\n",
        "owprecisionpneumonia=owerlapconf_mat[2,2]/(owerlapconf_mat[2,2]+owerlapconf_mat[1,2]+owerlapconf_mat[0,2])\n",
        "\n",
        "owf1normal=2*(owrecallnormal*owprecisionnormal)/(owrecallnormal+owprecisionnormal)\n",
        "owf1covid=2*(owrecallcovid*owprecisioncovid)/(owrecallcovid+owprecisioncovid)\n",
        "owf1pneumonia=2*(owrecallpneumonia*owprecisionpneumonia)/(owrecallpneumonia+owprecisionpneumonia)\n",
        "\n",
        "print(\"Owerlap Recall Normal=\",owrecallnormal)\n",
        "print(\"Owerlap Recall Covid=\",owrecallcovid)\n",
        "print(\"Owerlap Recall Pneumonia=\",owrecallpneumonia)\n",
        "\n",
        "print(\"Owerlap Precision Normal=\",owprecisionnormal)\n",
        "print(\"Owerlap Precision Covid=\",owprecisioncovid)\n",
        "print(\"Owerlap Precision Pneumonia=\",owprecisionpneumonia)\n",
        "\n",
        "\n",
        "print(\"Owerlap  F1-Score Normal=\",owf1normal)\n",
        "print(\"Owerlap  F1-Score Covid=\",owf1covid)\n",
        "print(\"Owerlap  F1-Score Pneumonia=\",owf1pneumonia)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYFN6BGQXoPb"
      },
      "source": [
        "#Plot Accuracy and Loss Curve\n",
        "#%load_ext autotime\n",
        "import json,codecs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "n=np.load(\"drive/My Drive/LargeDataSetBen/modelsmodify/my_historyk2.npy\",allow_pickle='TRUE').item()\n",
        "plt.plot(n['loss'],label='train loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(n['accuracy'],label='train acc')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_eKVK1cBVNd"
      },
      "source": [
        "pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aH4D9-aNuI3"
      },
      "source": [
        "!pip install ipython-autotime"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}